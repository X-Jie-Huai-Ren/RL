{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  4 , output_dim:  2 , hidden_dim:  32\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import FloatTensor\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "from ddqnAgents import QNetAgent\n",
    "from replay_buffer import ReplayMemory, Transition\n",
    "\n",
    "# setup matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: \n",
    "    from IPython import display\n",
    "# 动态图\n",
    "plt.ion()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# 参数设置\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "gamma = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPFATE = 10\n",
    "num_episodes = 20000\n",
    "print_every = 10\n",
    "hidden_dim = 32\n",
    "min_eps = 0.01\n",
    "max_eps_episode = 150\n",
    "\n",
    "# 环境\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.wrappers.RecordVideo(env, directory='monitors', force=True)\n",
    "\n",
    "space_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "print('input_dim: ', space_dim, ', output_dim: ', action_dim, ', hidden_dim: ', hidden_dim)\n",
    "\n",
    "agent = QNetAgent(n_states=space_dim, n_actions=action_dim, hidden_dim=hidden_dim)\n",
    "\n",
    "\n",
    "# 权重衰减\n",
    "def epsilon_annealing(i_episode, max_episode, min_eps:float):\n",
    "    slope = (min_eps - 1.0) / max_episode\n",
    "    ret_eps = max(slope*i_episode+1.0, min_eps)\n",
    "    return ret_eps\n",
    "\n",
    "# 保存权重\n",
    "def save(directory, filename):\n",
    "    torch.save(agent.q_local.state_dict(), '{0}/{1}_local.pth'.format(directory, filename))\n",
    "    torch.save(agent.q_target.state_dict(), '%s/%s_target.pth' % (directory, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Single episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04846687  0.0403985  -0.03763504  0.02360786]\n"
     ]
    }
   ],
   "source": [
    "def run_episode(env, agent, eps):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        env (gym.Env): gym environment (CartPole-v0)\n",
    "        agent (Agent): agent will train and get action        \n",
    "        eps (float): eps-greedy for exploration\n",
    "\n",
    "    returns:\n",
    "        int: return earned in this episode\n",
    "    \"\"\"\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    print(state)\n",
    "\n",
    "    while not done:\n",
    "        # 根据当前状态采取action\n",
    "        action = agent.get_action(FloatTensor([state]), eps)\n",
    "\n",
    "        next_state, reward, done, info, _ = env.step(action)\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        # 结束收到惩罚\n",
    "        if done:\n",
    "            reward = -1\n",
    "\n",
    "        # Store the transition in memory\n",
    "        agent.replay_memory.push(\n",
    "            (FloatTensor([state]), \n",
    "            action,                    # action is already a tensor\n",
    "            FloatTensor([reward]), \n",
    "            FloatTensor([next_state]), \n",
    "            FloatTensor([done]))\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "run_episode(env, agent, eps=0.0001)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
